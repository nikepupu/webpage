<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Xiaofeng&#39;s Blog">
    <meta name="author" content="Xiaofeng Gao">

    <title>Xiaofeng Gao</title>

    <!-- Bootstrap Core CSS -->
    <link href="./css/bootstrap.min.css" rel="stylesheet">

    <!-- Main CSS -->
    <link href="./css/main.css" rel="stylesheet">

    <!-- Font Awesome CSS -->
    <link rel="stylesheet" href="./css/font-awesome.min.css">

    <!-- icon -->
    <link rel="shortcut icon" href="http://web.cs.ucla.edu/favicon.ico" type="image/x-icon">
    <link rel="icon" href="http://web.cs.ucla.edu/favicon.ico" type="image/x-icon">

    <!-- Google Fonts -->
    <link rel="stylesheet" href="./css/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<!-- The #page-top ID is part of the scrolling feature - the data-spy and data-target are part of the built-in Bootstrap scrollspy function -->

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top navbar-inverse bg-inverse top-nav-collapse" role="navigation">
        <div class="container">
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="http://xfgao.github.io/#page-top">Xiaofeng Gao</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden active">
                        <a class="page-scroll" href="http://xfgao.github.io/#page-top"></a>
                    </li>
                    <li class="">
                        <a class="page-scroll" href="http://xfgao.github.io/#about">About</a>
                    </li>
<!--                     <li>
                        <a class="page-scroll" href="#projects">Projects</a>
                    </li> -->
                    <li class="">
                        <a class="page-scroll" href="http://xfgao.github.io/#publications">Publications</a>
                    </li>
<!--                     <li>
                        <a class="page-scroll" href="#awards">Awards</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#resume">Resume</a>
                    </li>
 -->                </ul>
<!--                 <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="mailto:xfgao@ucla.edu" class="navbar-brand"><i class="fa fa-envelope"></i></a>
                    </li>
                    <li>
                        <a href="https://github.com/xfgao/" class="navbar-brand"><i class="fa fa-github"></i></a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=AjTfCjEAAAAJ&hl=en&authuser=1" class="navbar-brand"><i class="fa fa-graduation-cap"></i></a>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/xiaofeng-gao-09b966115/" class="navbar-brand"><i class="fa fa-linkedin"></i></a>
                    </li>
                    <li>
                        <a href="https://www.facebook.com/profile.php?id=100010717656664" class="navbar-brand"><i class="fa fa-facebook"></i></a>
                    </li>

                </ul> -->

            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Section -->
    <section id="intro" class="intro-section">
        <div class="container">
            <div class="row">
                <div class="col-xs-12 col-sm-6 col-md-5 col-lg-4">
                        <img src="./imgs/xfgao.jpg" class="img-responsive img-circle img-fluid" width="200">
                </div>
                <div class="col-xs-12 col-md-6 col-md-7 col-lg-8 personal-intro">
                    <div class="col-xs-12 col-sm-12 col-md-12">
                        <h2 class="text-uppercase">Xiaofeng Gao</h2>
                        <h2><small>Ph.D. Candidate in Statistics at UCLA</small></h2>
                        <address>
                            Boelter Hall 9407<br>
                            580 Portola Plaza<br>
                            University of California, Los Angeles<br>
                            Los Angeles, CA, 90095
                        </address>
                        <span><strong>Email: </strong>xfgao at ucla dot edu</span>
                        <br>
                        <a href="https://scholar.google.com/citations?user=AjTfCjEAAAAJ&hl=en&authuser=1">[Google Scholar]</a>&nbsp;&nbsp;
						<a href="https://github.com/xfgao">[GitHub]</a>
                    </div>
					
                </div>
            </div>
        </div>
    </section>
        <hr>
    <!-- About Section -->
    <section id="about" class="about-section">
        <div class="container">
            <h1>About</h1>
            <div class="bio-info">
                <p>I am a second year Ph.D. candidate in the Department of Statistics, UCLA. </p>
                My research lies in the intersection of Robotics, Computer Vision, Machine Learning and Cognitive Science. Currently I'm working in the <a href="http://vcla.stat.ucla.edu/">Center for Vision, Cognition, Learning, and Autonomy (VCLA)</a>, under the supervision of <a href="http://www.stat.ucla.edu/~sczhu/">Prof. Song-chun Zhu</a>. Before that, I obtained a bachelor degree of Electronic Engineering at Fudan University. 
            </div>

        </div>
    </section>
    <hr>

    <!-- Projects Section -->
<!--     <section id="projects" class="projects-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1>Projects</h1>
                </div>
            </div>
        </div>
    </section>
    <hr></hr> -->


    <section id="publications" class="publications-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1>Publications</h1>
                        <div class="contents">
                            <ul class="list-group">

                                <!-- Human-Robot Social Interaction -->
                                <li class="list-group-item">
                                    <div class="row">
                                        <div class="col-xs-12 col-sm-4 col-lg-2">
                                            <img src="./imgs/hri_intro.png" class="img-responsive img-fluid">
                                        </div>
                                        <div class="col-xs-12 col-sm-8 col-lg-10">
                                        <h4 class="list-group-item-heading">Learning Social Affordance Grammar from Videos: 
                                        	Transferring Human Interactions to Human-Robot Interactions 
                                        <span class="badge">
                                            <a class="conf" href="http://www.icra2017.org/">ICRA'19</a>
                                        </span></h4>
                                        <p class="detail">
                                            <a href="https://tshu.io">Tianmin Shu</a>,
                                            <strong>Xiaofeng Gao</strong>, 
                                            <a href="http://michaelryoo.com/">Michael S. Ryoo</a>,
                                            <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a><br>
                                            <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em> 2017
                                        </p>
                                        <button class="btn btn-success btn-xs" data-toggle="collapse" data-target="#social_interaction-abs">Abstract</button>
                                        <a class="btn btn-primary btn-xs" role="button" href="https://arxiv.org/pdf/1703.00503.pdf">PDF</a>
                                        <a class="btn btn-warning btn-xs" role="button" href="https://www.tshu.io/SocialAffordanceGrammar/index.html">Website</a> 
                                        </div>
                                    </div>
                                    <div id="social_interaction-abs" class="collapse abstract">
                                        In this paper, we present a general framework for learning social affordance grammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human interactions, and transfer the grammar to humanoids to enable a real-time motion inference for human-robot interaction (HRI). Based on Gibbs sampling, our weakly supervised grammar learning can automatically construct a hierarchical representation of an interaction with long-term joint sub-tasks of both agents and short term atomic actions of individual agents. Based on a new RGB-D video dataset with rich instances of human interactions, our experiments of Baxter simulation, human evaluation, and real Baxter test demonstrate that the model learned from limited training data successfully generates human-like behaviors in unseen scenarios and outperforms both baselines.
                                    </div>
                                </li>

                                <!-- VRKitchen -->
                                <li class="list-group-item">
                                    <div class="row">
                                        <div class="col-xs-12 col-sm-4 col-lg-2">
                                            <img src="./imgs/dish_fluent_small.gif" class="img-responsive img-fluid">
                                        </div>
                                        <div class="col-xs-12 col-sm-8 col-lg-10">
                                        <h4 class="list-group-item-heading">VRKitchen: an Interactive 3D Virtual Environment for Task-oriented Learning
                                        <span class="badge">
                                            <a class="conf" href="https://arxiv.org/abs/1903.05757">arXiv</a>
                                        </span></h4>
                                        <p class="detail">
                                            <strong>Xiaofeng Gao</strong>, 
                                            <a href="https://nikepupu.github.io/">Ran Gong</a>,
                                            <a href="https://tshu.io">Tianmin Shu</a>,
                                            <a href="https://xuxie1031.github.io/">Xu Xie</a>,
                                            <a href="https://shuwang0712.github.io/">Shu Wang</a>,
                                            <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a><br>
                                            <em>arXiv:1903.05757</em>
                                        </p>
                                        <button class="btn btn-success btn-xs" data-toggle="collapse" data-target="#kitchen-abs">Abstract</button>
                                        <a class="btn btn-primary btn-xs" role="button" href="https://arxiv.org/pdf/1903.05757.pdf">PDF</a>
                                        <a class="btn btn-warning btn-xs" role="button" href="https://sites.google.com/view/vr-kitchen/">Website</a> 
                                        </div>
                                    </div>
                                    <div id="kitchen-abs" class="collapse abstract">
                                        One of the main challenges of advancing task-oriented learning such as visual task planning and reinforcement learning is the lack of realistic and standardized environments for training and testing AI agents. Previously, researchers often relied on ad-hoc lab environments. There have been recent advances in virtual systems built with 3D physics engines and photo-realistic rendering for indoor and outdoor environments, but the embodied agents in those systems can only conduct simple interactions with the world (e.g., walking around, moving objects, etc.). Most of the existing systems also do not allow human participation in their simulated environments. In this work, we design and implement a virtual reality (VR) system, VRKitchen, with integrated functions which i) enable embodied agents powered by modern AI methods (e.g., planning, reinforcement learning, etc.) to perform complex tasks involving a wide range of fine-grained object manipulations in a realistic environment, and ii) allow human teachers to perform demonstrations to train agents (i.e., learning from demonstration). We also provide standardized evaluation benchmarks and data collection tools to facilitate a broad use in research on task-oriented learning and beyond.
                                    </div>
                                </li>

   
                            </ul>
                        </div>
                </div>
            </div>
        </div>
    </section>
    <hr>

    <footer class="footer">
        <div class="container">
            <p class="text-muted">© 2019 by Xiaofeng Gao. <span class="hidden-phone">All rights reserved</span></p>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="./css/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="./css/bootstrap.min.js"></script>

    <!-- Scrolling Nav JavaScript -->
    <script src="./css/jquery.easing.min.js"></script>
    <script src="./css/scrolling-nav.js"></script>




</body></html>